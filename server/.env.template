ENVIRONMENT="dev" # Set this to "prod" on your production server

# AZURE AI SERVICES
AZURE_OPENAI_API_KEY='{YOUR AZURE OPENAI SERVICE API KEY}'
AZURE_OPENAI_ENDPOINT='{YOUR AZURE ENDPOINT URL}'
# Use the same or different models for images vs text
AZURE_IMAGE_MODEL_OPTION='{YOUR AZURE IMAGE MODEL NAME}' #should match the chosen name of the deployed model (not model name)
AZURE_TEXT_MODEL_OPTION='{YOUR AZURE TEXT MODEL NAME}' #should match the chosen name of the deployed model (not model name)
# Azure API version (can be found here: https://learn.microsoft.com/en-gb/azure/ai-services/openai/how-to/switching-endpoints#api-key)
AZURE_API_VERSION='{YOUR AZURE API VERSION}' #e.g. "2024-07-01-preview"

# OPENAI AI SERVICES
OPENAI_API_KEY='{YOUR OPENAI API KEY}'
OPENAI_API_TYPE='openai' # Can be 'azure' or 'openai'
OPENAI_MODEL_OPTION='{YOUR OPENAI MODEL OPTION}' #recommended: 'gpt-4o'

# LOCAL AI SERCIVES (HuggingFace API key with permission to use meta-llama/Llama-3.2-11B-Vision)
HUGGINGFACE_API_KEY='{YOUR HUGGINGFACE API KEY WITH ADDED PERMISSIONS}'

# WEIGHTS & BIASES (Logging) (Optional)
WANDB__SERVICE_WAIT="300"
WANDB_MODE="offline" # "offline" for local logging only or "online" to sync each run with server